{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones para entrenamiento y testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_function(model, param_grid, X_train, y_train, pca_components=[0.50, 0.99], cv=2):\n",
    "    \"\"\"\n",
    "    Realiza una búsqueda en cuadrícula (grid search) con validación cruzada\n",
    "    para encontrar los mejores parámetros de un modelo de aprendizaje automático.\n",
    "\n",
    "    Parámetros:\n",
    "    - model: El modelo de aprendizaje automático a utilizar.\n",
    "    - param_grid (dict): Diccionario de parámetros a probar en la búsqueda en cuadrícula.\n",
    "    - X_train (array-like): Datos de entrenamiento.\n",
    "    - y_train (array-like): Etiquetas de entrenamiento.\n",
    "    - pca_components (list, opcional): Lista de componentes principales (PCA) a probar.\n",
    "      Predeterminado: [0.50, 0.99]\n",
    "    - cv (int, opcional): Número de divisiones para la validación cruzada. Predeterminado: 2.\n",
    "\n",
    "    Retorna:\n",
    "    tuple: Una tupla que contiene los mejores parámetros, la mejor puntuación,\n",
    "    el mejor estimador y los resultados de la validación cruzada.\n",
    "    \"\"\"\n",
    "    # Configura el pipeline con las funciones de PCA y el modelo de aprendizaje automático\n",
    "    pipeline = Pipeline([\n",
    "        ('pca', PCA()),\n",
    "        ('classify', model)\n",
    "    ])\n",
    "\n",
    "    # Realiza la búsqueda en cuadrícula con validación cruzada utilizando el pipeline anterior\n",
    "    # y los parámetros del modelo específico\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=cv, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Obtiene los mejores parámetros del modelo específico\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Elimina el prefijo 'classify__' de todas las claves\n",
    "    best_params = {key.replace('classify__', '', 1): value for key, value in best_params.items()}\n",
    "\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, best_params=None):\n",
    "    \"\"\"\n",
    "    Entrena un modelo de aprendizaje automático, opcionalmente utilizando los mejores\n",
    "    parámetros obtenidos de una búsqueda en cuadrícula (grid search).\n",
    "\n",
    "    Parámetros:\n",
    "    - model: El modelo de aprendizaje automático a entrenar.\n",
    "    - best_params (dict, opcional): Diccionario con los mejores parámetros para el modelo.\n",
    "      Si no se proporciona, se entrenará el modelo con los parámetros predeterminados.\n",
    "\n",
    "    Retorna:\n",
    "    - El modelo entrenado.\n",
    "    \"\"\"\n",
    "    # Si se proporcionan los mejores parámetros, se establecen en el modelo\n",
    "    if best_params is not None:\n",
    "        model.set_params(**best_params)\n",
    "\n",
    "    # Entrena el modelo con los datos de entrenamiento\n",
    "    return model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, is_classification=False):\n",
    "    \"\"\"\n",
    "    Evalúa el rendimiento de un modelo de aprendizaje automático en un conjunto de prueba.\n",
    "    Puede manejar tanto modelos de clasificación como de regresión.\n",
    "\n",
    "    Parámetros:\n",
    "    - model: El modelo de aprendizaje automático a evaluar.\n",
    "    - is_classification (bool, opcional): Indica si el modelo es de clasificación.\n",
    "      Predeterminado: False (regresión).\n",
    "\n",
    "    Retorna:\n",
    "    - y_pred: Las predicciones del modelo en el conjunto de prueba.\n",
    "    \"\"\"\n",
    "    # Realiza las predicciones del modelo en el conjunto de prueba\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Si el modelo es de clasificación, calcula y muestra la precisión\n",
    "    if is_classification:\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Precisión del modelo: {acc}\")\n",
    "    # Si el modelo es de regresión, calcula y muestra el error cuadrático medio y el R²\n",
    "    else:\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        print(f'Error Cuadrático Medio en el conjunto de prueba: {mse:.2f}')\n",
    "        print(f'Coeficiente de Determinación (R²): {r2:.2f}')\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separacion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separo las las variables de la variable target\n",
    "X = df_estandarizado_escalado.drop(columns=['subscribed_encoded'])\n",
    "y = df_estandarizado_escalado['subscribed_encoded']\n",
    "# Divido las variable target y el resto de variables en testeo y prueba utilizando un 35% de datos para prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instancia y evaluacion de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo de bosques aleatorios:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo instancia del modelo random forest\n",
    "random_forest_model = RandomForestClassifier()\n",
    "\n",
    "# Parametros y rango de valores para el modelo de random forest\n",
    "random_forest_params_grid = {\n",
    "    'classify__max_depth': [None, 5, 10],\n",
    "    'classify__min_samples_split': [2, 5, 10],\n",
    "    'classify__min_samples_leaf': [1, 2, 4],\n",
    "    'classify__ccp_alpha': [0.0, 0.1, 0.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtengo los mejores parametros desde grid search\n",
    "random_forest_best_params_grid = grid_search_function(model= random_forest_model, param_grid=random_forest_params_grid, X_train=X_train, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entreno el modelo con los mejores parametros previamente obtenidos\n",
    "random_forest_model = train(random_forest_model, random_forest_best_params_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 0.8983768035516093\n"
     ]
    }
   ],
   "source": [
    "# obtengo las predicciones del modelo\n",
    "y_pred = test(random_forest_model, is_classification=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo de regresion logistica:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo una instancia del modelo de regresion logistica\n",
    "logistic_regression_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defino el rango de valores para evaluar los parametros del modelo\n",
    "logistic_regression_params_grid = {\n",
    "    'classify__penalty': ['l1', 'l2'],\n",
    "    'classify__C': [0.1, 1, 10],\n",
    "    'classify__fit_intercept': [True, False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "12 fits failed out of a total of 24.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 427, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.89929777        nan 0.76333483        nan 0.89903631\n",
      "        nan 0.77674436        nan 0.89907366        nan 0.77909756]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# obtengo los mejores parametros para el modelo\n",
    "logistic_regression_best_params_grid = grid_search_function(logistic_regression_model, logistic_regression_params_grid, X_train=X_train, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# entreno el modelo con los mejores parametros obtenidos\n",
    "logistic_regression_model = train(logistic_regression_model, logistic_regression_best_params_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 0.8979605993340732\n"
     ]
    }
   ],
   "source": [
    "# evaluo la presicion del modelo de regresion logistica\n",
    "y_test = test(logistic_regression_model, is_classification=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardado del mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/content/models/random_forest_model_subscribed.pkl']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Guardar el modelo entrenado en un archivo .pkl\n",
    "path_best_ml_model = '/content/models/random_forest_model_subscribed.pkl'\n",
    "joblib.dump(random_forest_model, path_best_ml_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observaciones de esta etapa:\n",
    "\n",
    "El modelo que presenta el mayor porcentaje de precisión es el de **Bosques Aleatorios, con una precisión del 89.83%** para la variable objetivo subscribed."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
